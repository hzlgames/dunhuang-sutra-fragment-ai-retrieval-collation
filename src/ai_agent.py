import os
import json
import textwrap
import time
import uuid
from typing import List, Dict, Any, Optional, Generator, Callable
from datetime import datetime
from pathlib import Path
from pydantic import BaseModel, Field
from google import genai
from google.genai import types

from src.cbeta_tools import CBETATools
from src.gallica_client import GallicaClient
from src.gallica_mcp import GallicaMCPClient, MCPConfig
from src.schemas import FinalAnswer, ScriptureLocation, OCRResult

StreamHandler = Callable[[str, Dict[str, Any]], None]

class AgentConfig(BaseModel):
    """Agent é…ç½®"""
    thinking_level: str = "high"  # "low" or "high"
    max_tool_rounds: int = 5  # æœ€å¤šå·¥å…·è°ƒç”¨è½®æ•°ï¼ˆä¸å«æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºè½®ï¼‰
    retry_interval: int = 10  # é‡è¯•é—´éš”ç§’æ•°
    normal_retries: int = 3  # æ™®é€šè½®é‡è¯•æ¬¡æ•°
    final_retries: int = 5  # æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºè½®é‡è¯•æ¬¡æ•°
    timeout_seconds: int = 120
    model_name: str = "gemini-3-pro-preview"
    verbose: bool = True  # æ˜¯å¦å¼€å¯å¯è§†åŒ–è¾“å‡º
    # Gallica MCP é…ç½®
    gallica_mcp_enabled: bool = True  # æ˜¯å¦å¯ç”¨ Gallica MCP
    gallica_mcp_path: str = ""  # sweet-bnf é¡¹ç›®è·¯å¾„ï¼ˆç•™ç©ºåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰

class SessionManager:
    """ä¼šè¯ç®¡ç†å™¨"""
    def __init__(self, storage_dir: str = "sessions"):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)

    def create_session(self) -> str:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session_id = str(uuid.uuid4())
        self.save_session(session_id, [])
        return session_id

    def save_session(self, session_id: str, history: List[Dict]):
        """ä¿å­˜ä¼šè¯å†å²"""
        file_path = self.storage_dir / f"{session_id}.json"
        data = {
            "session_id": session_id,
            "updated_at": datetime.now().isoformat(),
            "history_count": len(history)  # ç®€åŒ–ï¼šåªä¿å­˜æ•°é‡ï¼Œä¸ä¿å­˜å®Œæ•´å†å²
        }
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def load_session(self, session_id: str) -> List[Dict]:
        """åŠ è½½ä¼šè¯å†å²"""
        # ç®€åŒ–ç‰ˆï¼šä¸å®é™…åŠ è½½å†å²
        return []

    def _rounds_path(self, session_id: str) -> Path:
        return self.storage_dir / f"{session_id}.rounds.jsonl"

    def save_round(self, session_id: str, payload: Dict[str, Any]):
        """å°†å•è½®æ‘˜è¦å†™å…¥ JSONL æ–‡ä»¶"""
        file_path = self._rounds_path(session_id)
        try:
            with open(file_path, "a", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False)
                f.write("\n")
        except OSError as exc:
            print(f"âš ï¸ ä¿å­˜è½®æ¬¡è®°å½•å¤±è´¥: {exc}")

    def load_rounds(self, session_id: str) -> List[Dict[str, Any]]:
        """è¯»å–æŒ‡å®šä¼šè¯çš„è½®æ¬¡è®°å½•"""
        file_path = self._rounds_path(session_id)
        rounds: List[Dict[str, Any]] = []
        if not file_path.exists():
            return rounds

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        rounds.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
        except OSError as exc:
            print(f"âš ï¸ è¯»å–è½®æ¬¡è®°å½•å¤±è´¥: {exc}")
            return rounds

        return sorted(rounds, key=lambda record: record.get("round_index", 0))


def build_round_history_contents(round_records: List[Dict[str, Any]]) -> List[types.Content]:
    """å°†è½®æ¬¡è®°å½•è½¬æ¢ä¸º Gemini å¯ç”¨çš„å†å²æ¶ˆæ¯"""
    contents: List[types.Content] = []
    for record in round_records:
        round_index = record.get("round_index", "?")
        segments: List[str] = []
        summary = (record.get("summary") or "").strip()
        segments.append(
            f"ã€å†å²ç¬¬ {round_index} è½®æ‘˜è¦ã€‘{summary or 'æœªæä¾›æ‘˜è¦'}"
        )

        tool_calls = record.get("tool_calls") or []
        if tool_calls:
            tools_desc = []
            for call in tool_calls:
                name = call.get("name", "unknown")
                args = call.get("args", {})
                try:
                    args_str = json.dumps(args, ensure_ascii=False)
                except (TypeError, ValueError):
                    args_str = str(args)

                result_summary = call.get("result_summary", "")
                tools_desc.append(f"{name}({args_str}) â†’ {result_summary}")
            segments.append("å·¥å…·è°ƒç”¨: " + " | ".join(tools_desc))

        notes = record.get("notes") or []
        for note in notes:
            segments.append(f"å¤‡æ³¨: {note}")

        contents.append(types.Content(role="user", parts=[types.Part(text="\n".join(segments))]))

    return contents

class CBETAAgent:
    def __init__(self, config: Optional[AgentConfig] = None):
        """
        åˆå§‹åŒ– CBETA æ™ºèƒ½ä»£ç†ï¼ŒåŠ è½½ Gemini Clientã€å·¥å…·æ˜ å°„ä¸ä¼šè¯ç®¡ç†å™¨ã€‚
        å‚æ•°ä¿æŒä¸ test_gemini3 ä¸€è‡´ï¼ˆmodel=gemini-3-pro-previewã€temperature=1.0ã€é»˜è®¤ high æ€è€ƒç­‰çº§ï¼‰ã€‚
        """
        self.config = config or AgentConfig()
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY æœªé…ç½®ï¼Œæ— æ³•åˆå§‹åŒ– CBETAAgentã€‚")

        self.client = genai.Client(api_key=api_key)
        self.session_manager = SessionManager()
        self.cbeta_tools = CBETATools()
        
        # åˆå§‹åŒ– Gallica å®¢æˆ·ç«¯ï¼ˆä¼˜å…ˆ MCPï¼Œå›é€€æœ¬åœ°ï¼‰
        self.gallica_fallback = GallicaClient()
        mcp_config = MCPConfig(
            server_path=self.config.gallica_mcp_path or os.getenv("GALLICA_MCP_PATH", ""),
            enabled=self.config.gallica_mcp_enabled,
        )
        self.gallica_client = GallicaMCPClient(config=mcp_config, fallback=self.gallica_fallback)
        
        if self.config.verbose:
            if self.gallica_client.is_mcp_available:
                print(f"ğŸ”— Gallica MCP å·²è¿æ¥ï¼Œå¯ç”¨å·¥å…·: {self.gallica_client.available_tools}")
            else:
                print("â„¹ï¸ Gallica ä½¿ç”¨æœ¬åœ°å›é€€æ¨¡å¼")

        self.tools_map = {
            # ===== CBETA å·¥å…· =====
            "search_full_text": self.cbeta_tools.search_full_text,
            "search_advanced": self.cbeta_tools.search_advanced,
            "search_similar": self.cbeta_tools.search_similar,
            "search_title": self.cbeta_tools.search_title,
            "search_kwic": self.cbeta_tools.search_kwic,
            "search_toc": self.cbeta_tools.search_toc,
            "search_notes": self.cbeta_tools.search_notes,
            "search_variants": self.cbeta_tools.search_variants,
            "get_facet_stats": self.cbeta_tools.get_facet_stats,
            # ===== Gallica å·¥å…·ï¼ˆé€šè¿‡ MCP æˆ–å›é€€ï¼‰ =====
            "search_gallica": self.gallica_client.search,
            "search_gallica_dunhuang": self.gallica_client.search_dunhuang,
            "search_gallica_by_title": self.gallica_client.search_by_title,
            "search_gallica_by_author": self.gallica_client.search_by_author,
            "search_gallica_by_subject": self.gallica_client.search_by_subject,
            "search_gallica_advanced": self.gallica_client.search_advanced,
            "get_gallica_manifest": self.gallica_client.get_manifest,
            "get_gallica_pages": self.gallica_client.get_item_pages,
            "get_gallica_page": self.gallica_client.get_page_info,
            "get_gallica_page_text": self.gallica_client.get_page_text,
        }
        self.tools_declarations = self._init_tools_declarations()

    def _call_with_retry(self, func, *args, max_retries: int = 3, retry_interval: int = 30, **kwargs):
        """
        é€šç”¨é‡è¯•åŒ…è£…ï¼Œé€‚ç”¨äº Gemini API è°ƒç”¨ã€‚
        Args:
            func: è¦è°ƒç”¨çš„å‡½æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
            retry_interval: é‡è¯•é—´éš”ç§’æ•°ï¼ˆé»˜è®¤30ç§’ï¼‰
        """
        attempt = 0
        while attempt <= max_retries:
            try:
                return func(*args, **kwargs)
            except Exception as e:
                attempt += 1
                if attempt > max_retries:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries}): {e}")
                    raise
                print(f"âŒ API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                print(f"â³ ç­‰å¾… {retry_interval}s åé‡è¯•...")
                time.sleep(retry_interval)
        raise RuntimeError("API è°ƒç”¨å…¨éƒ¨é‡è¯•å¤±è´¥")

    def _emit_event(self, event_type: str, payload: Dict[str, Any], handler: Optional[StreamHandler]):
        """ç»Ÿä¸€çš„æµå¼äº‹ä»¶åˆ†å‘ã€‚"""
        if handler:
            handler(event_type, payload)
            return
        if not self.config.verbose:
            return

        if event_type == "thought":
            print(f"\nğŸ§  æ€è€ƒç‰‡æ®µ: {payload.get('text', '').strip()}")
        elif event_type == "tool_call":
            print(f"\nğŸ¤– å‡†å¤‡è°ƒç”¨å·¥å…· {payload.get('name')}: {payload.get('args')}")
        elif event_type == "tool_result":
            status = payload.get("status", "success")
            print(f"ğŸ“¥ å·¥å…· {payload.get('name')} å®Œæˆ ({status})")
            if "summary" in payload:
                print(f"   æ‘˜è¦: {payload['summary']}")
        elif event_type == "text":
            print(f"ğŸ’¬ è¾“å‡ºç‰‡æ®µ: {payload.get('text', '').strip()}")
        elif event_type == "error":
            print(f"âš ï¸  {payload.get('message')}")

    def _collect_parts_from_chunk(
        self,
        chunk: types.GenerateContentResponse,
        stream_handler: Optional[StreamHandler],
    ) -> List[types.Part]:
        """åˆ†æå•ä¸ªæµå¼ chunkï¼Œè¿”å›å…¶æ–°å¢ partsã€‚"""
        collected: List[types.Part] = []
        if not chunk.candidates:
            return collected

        candidate = chunk.candidates[0]
        content = candidate.content
        if not content or not content.parts:
            return collected

        for part in content.parts:
            collected.append(part)
            if getattr(part, "thought", False):
                self._emit_event("thought", {"text": part.text or ""}, stream_handler)
            elif part.function_call:
                raw_args = part.function_call.args or {}
                if hasattr(raw_args, "items"):
                    args_view = {k: v for k, v in raw_args.items()}
                else:
                    args_view = raw_args
                self._emit_event(
                    "tool_call",
                    {"name": part.function_call.name, "args": args_view},
                    stream_handler,
                )
            elif part.text:
                self._emit_event("text", {"text": part.text}, stream_handler)
        return collected

    def _consume_stream(
        self,
        stream: Generator[types.GenerateContentResponse, None, None],
        stream_handler: Optional[StreamHandler],
    ) -> Optional[types.GenerateContentResponse]:
        """æ¶ˆè´¹ generate_content_stream è¿­ä»£å™¨ï¼Œèšåˆ parts å¹¶å¹¿æ’­äº‹ä»¶ã€‚"""
        aggregated_parts: List[types.Part] = []
        last_chunk: Optional[types.GenerateContentResponse] = None

        for chunk in stream:
            last_chunk = chunk
            aggregated_parts.extend(
                self._collect_parts_from_chunk(chunk, stream_handler)
            )

        if not last_chunk:
            return None

        response = last_chunk.model_copy(deep=True)
        if response.candidates and response.candidates[0].content:
            response.candidates[0].content.parts = aggregated_parts
        elif response.candidates:
            response.candidates[0].content = types.Content(
                role="model", parts=aggregated_parts
            )
        return response

    def _generate_with_stream(
        self,
        *,
        contents: List[types.Content],
        config: types.GenerateContentConfig,
        stream_handler: Optional[StreamHandler],
    ) -> Optional[types.GenerateContentResponse]:
        stream = self.client.models.generate_content_stream(
            model=self.config.model_name,
            contents=contents,
            config=config,
        )
        return self._consume_stream(stream, stream_handler)


    def _init_tools_declarations(self) -> List[Dict]:
        """å®šä¹‰ Gemini å·¥å…·å£°æ˜"""
        return [
            {
                "function_declarations": [
                    # ===== æ ¸å¿ƒæ£€ç´¢å·¥å…· =====
                    {
                        "name": "search_full_text",
                        "description": "ã€å…¨æ–‡æ£€ç´¢ã€‘åœ¨ CBETA å…¨åº“è¿›è¡Œå…³é”®è¯æœç´¢ã€‚è¿”å›åŒ¹é…çš„ç»å·åˆ—è¡¨åŠä¸Šä¸‹æ–‡ç‰‡æ®µã€‚é€‚ç”¨åœºæ™¯ï¼šå·²çŸ¥å…³é”®è¯ï¼Œéœ€è¦æ‰¾å‡ºæ‰€æœ‰å‡ºå¤„ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "æœç´¢å…³é”®è¯ï¼ˆç®€ç¹çš†å¯ï¼Œç³»ç»Ÿè‡ªåŠ¨è½¬æ¢ï¼‰"},
                                "rows": {"type": "INTEGER", "description": "è¿”å›æ•°é‡ï¼ˆé»˜è®¤20ï¼‰"},
                                "canon": {"type": "STRING", "description": "é™åˆ¶è—ç»ç‰ˆæœ¬ï¼šT=å¤§æ­£è—, X=åç»­è—, J=å˜‰å…´è—, H=æ­£å²ä½›æ•™èµ„æ–™, A=èµµåŸé‡‘è— ç­‰"},
                                "category": {"type": "STRING", "description": "é™åˆ¶éƒ¨ç±»ï¼ˆå¦‚ï¼šé˜¿å«éƒ¨ç±»ã€èˆ¬è‹¥éƒ¨ç±»ã€åä¸¥éƒ¨ç±»ï¼‰"},
                                "dynasty": {"type": "STRING", "description": "é™åˆ¶æœä»£ï¼ˆå¦‚ï¼šå”ã€å®‹ã€éš‹ï¼‰"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "search_advanced",
                        "description": "ã€é«˜çº§æ£€ç´¢ã€‘æ”¯æŒå¤æ‚å¸ƒå°”è¯­æ³•çš„æ•´åˆæ£€ç´¢ï¼ŒåŒæ—¶è¿”å› KWIC å‰åæ–‡å’Œåˆ†ç±»ç»Ÿè®¡ã€‚è¯­æ³•ï¼šç©ºæ ¼=AND, |=OR, !=NOT, NEAR/n=é‚»è¿‘ã€‚é€‚ç”¨åœºæ™¯ï¼šéœ€è¦ç²¾ç¡®ç»„åˆå¤šä¸ªæ¡ä»¶ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "é«˜çº§æŸ¥è¯¢ä¸²ã€‚ç¤ºä¾‹ï¼š'\"æ³•é¼“\" \"è–åš´\"'(AND), '\"æ³¢ç¾…èœœ\"|\"æ³¢ç¾…å¯†\"'(OR), '\"æ³•é¼“\" NEAR/7 \"è¿¦è‘‰\"'(é‚»è¿‘7å­—å†…)"},
                                "facet": {"type": "BOOLEAN", "description": "æ˜¯å¦è¿”å›è—ç»/éƒ¨ç±»/æœä»£/ä½œè€…ç»Ÿè®¡ï¼ˆé»˜è®¤trueï¼‰"},
                                "around": {"type": "INTEGER", "description": "KWIC ä¸Šä¸‹æ–‡å­—æ•°ï¼ˆé»˜è®¤15ï¼‰"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "search_similar",
                        "description": "ã€ç›¸ä¼¼æ–‡æœ¬æœç´¢ã€‘åŸºäº Smith-Waterman ç®—æ³•æŸ¥æ‰¾ç›¸ä¼¼æ®µè½ã€‚é€‚ç”¨åœºæ™¯ï¼šè¾“å…¥ OCR è¯†åˆ«çš„é•¿æ–‡æœ¬ï¼ˆ6-50å­—ï¼‰ï¼Œæ‰¾å‡º CBETA ä¸­ç›¸ä¼¼çš„ç»æ–‡æ®µè½ã€‚å¯¹ OCR é”™å­—æœ‰ä¸€å®šå®¹é”™ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "text": {"type": "STRING", "description": "æ–‡æœ¬ç‰‡æ®µï¼ˆå»ºè®®6-50å­—ï¼Œä¸å«æ ‡ç‚¹ï¼‰"},
                                "score_min": {"type": "INTEGER", "description": "æœ€ä½åŒ¹é…åˆ†æ•°ï¼ˆé»˜è®¤16ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼ï¼‰"}
                            },
                            "required": ["text"]
                        }
                    },
                    # ===== ç²¾ç¡®å®šä½å·¥å…· =====
                    {
                        "name": "search_title",
                        "description": "ã€ç»åæœç´¢ã€‘ä»…æœç´¢ä½›å…¸æ ‡é¢˜ï¼ˆç»åï¼‰ï¼Œå¿«é€ŸæŸ¥æ‰¾ç‰¹å®šç»å…¸ã€‚é€‚ç”¨åœºæ™¯ï¼šçŸ¥é“ç»åä½†ä¸ç¡®å®šå®Œæ•´åç§°æˆ–ç»å·ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "ç»åå…³é”®è¯ï¼ˆå¦‚ï¼šé‡‘åˆšç»ã€é˜¿å«ã€åä¸¥ï¼‰"},
                                "rows": {"type": "INTEGER", "description": "è¿”å›æ•°é‡ï¼ˆé»˜è®¤20ï¼‰"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "search_kwic",
                        "description": "ã€å•å·ç²¾ç¡®æ£€ç´¢ã€‘é’ˆå¯¹ç‰¹å®šä½›å…¸çš„ç‰¹å®šå·è¿›è¡Œ KWIC æ£€ç´¢ï¼Œè¿”å›æ‰€æœ‰åŒ¹é…ä½ç½®åŠå‰åæ–‡ã€‚é€‚ç”¨åœºæ™¯ï¼šå·²çŸ¥ç»å·å’Œå·å·ï¼Œéœ€è¦ç²¾ç¡®å®šä½å…³é”®è¯åœ¨è¯¥å·ä¸­çš„ä½ç½®ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "work": {"type": "STRING", "description": "ä½›å…¸ç¼–å·ï¼ˆå¦‚ï¼šT0001, T0235, X0087ï¼‰"},
                                "juan": {"type": "INTEGER", "description": "å·å·ï¼ˆå¦‚ï¼š1, 2, 3ï¼‰"},
                                "query": {"type": "STRING", "description": "å…³é”®è¯ï¼Œå¤šè¯ç”¨é€—å·åˆ†éš”"},
                                "around": {"type": "INTEGER", "description": "å‰åæ–‡å­—æ•°ï¼ˆé»˜è®¤15ï¼‰"},
                                "include_notes": {"type": "BOOLEAN", "description": "æ˜¯å¦åŒ…å«å¤¹æ³¨ï¼ˆé»˜è®¤trueï¼‰"}
                            },
                            "required": ["work", "juan", "query"]
                        }
                    },
                    {
                        "name": "search_toc",
                        "description": "ã€ç›®å½•æœç´¢ã€‘æœç´¢ç»åã€éƒ¨ç±»ç›®å½•æˆ–ä½›å…¸å†…ç›®æ¬¡ç»“æ„ã€‚é€‚ç”¨åœºæ™¯ï¼šæŸ¥æ‰¾æŸéƒ¨ç»çš„ç« èŠ‚ç»“æ„ï¼Œæˆ–æŒ‰éƒ¨ç±»æµè§ˆã€‚è¿”å›ç±»å‹ï¼šcatalog(éƒ¨ç±»ç›®å½•)ã€work(ä½›å…¸æ ‡é¢˜)ã€toc(å†…éƒ¨ç›®æ¬¡)ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "æœç´¢è¯ï¼ˆå¦‚ï¼šé˜¿å«ã€èˆ¬è‹¥ã€æ¶…æ§ƒï¼‰"},
                                "rows": {"type": "INTEGER", "description": "è¿”å›æ•°é‡ï¼ˆé»˜è®¤20ï¼‰"}
                            },
                            "required": ["query"]
                        }
                    },
                    # ===== è¾…åŠ©ç ”ç©¶å·¥å…· =====
                    {
                        "name": "search_notes",
                        "description": "ã€æ³¨è§£æ£€ç´¢ã€‘ä¸“é—¨æœç´¢æ ¡å‹˜æ¡ç›®ã€æ³¨è§£æˆ–å¤¹æ³¨ã€‚æ”¯æŒé«˜çº§è¯­æ³•ã€‚é€‚ç”¨åœºæ™¯ï¼šæŸ¥æ‰¾æŸè¯åœ¨æ ¡å‹˜/æ³¨è§£ä¸­çš„å‡ºç°ï¼Œç ”ç©¶ç‰ˆæœ¬å·®å¼‚ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "æœç´¢è¯ï¼ˆæ”¯æŒ AND/OR/NOT/NEAR è¯­æ³•ï¼‰"},
                                "facet": {"type": "BOOLEAN", "description": "æ˜¯å¦è¿”å›åˆ†ç±»ç»Ÿè®¡ï¼ˆé»˜è®¤falseï¼‰"},
                                "rows": {"type": "INTEGER", "description": "è¿”å›æ•°é‡ï¼ˆé»˜è®¤20ï¼‰"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "search_variants",
                        "description": "ã€å¼‚ä½“å­—æŸ¥è¯¢ã€‘åˆ—å‡ºå…³é”®è¯çš„æ‰€æœ‰å¼‚ä½“å­—å˜åŒ–ã€‚é€‚ç”¨åœºæ™¯ï¼šOCR ç»“æœå¯èƒ½æœ‰å¼‚ä½“å­—ï¼ˆå¦‚ï¼šè‘—/ç€ã€é‰¢/é’µï¼‰ï¼Œå…ˆç”¨æ­¤å·¥å…·è·å–å˜ä½“å†æœç´¢å¯æé«˜å¬å›ç‡ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "åŸå§‹è¯ï¼ˆå¦‚ï¼šè‘—è¡£æŒé‰¢ï¼‰"},
                                "scope": {"type": "STRING", "description": "å¯é€‰ 'title' ä»…åˆ—å‡ºä½›å…¸é¢˜åä¸­çš„å¼‚ä½“å­—"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "get_facet_stats",
                        "description": "ã€ç»Ÿè®¡åˆ†æã€‘è·å–å…³é”®è¯åœ¨ä¸åŒç»´åº¦ä¸‹çš„åˆ†å¸ƒç»Ÿè®¡ã€‚é€‚ç”¨åœºæ™¯ï¼šäº†è§£æŸè¯åœ¨å„è—ç»/éƒ¨ç±»/æœä»£/ä½œè€…ä¸­çš„ä½¿ç”¨é¢‘ç‡åˆ†å¸ƒã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "æœç´¢è¯"},
                                "facet_type": {"type": "STRING", "description": "ç»´åº¦ç±»å‹ï¼šcanon(è—ç»)ã€category(éƒ¨ç±»)ã€creator(ä½œè¯‘è€…)ã€dynasty(æœä»£)ã€work(ä½›å…¸)ã€‚ç•™ç©ºè¿”å›æ‰€æœ‰ç»´åº¦ã€‚"}
                            },
                            "required": ["query"]
                        }
                    },
                    # ===== Gallica å·¥å…·ï¼ˆæ³•å›½å›½å®¶å›¾ä¹¦é¦†æ•¦ç…Œæ–‡çŒ®ï¼‰ =====
                    {
                        "name": "search_gallica",
                        "description": "ã€Gallica æœç´¢ã€‘åœ¨æ³•å›½å›½å®¶å›¾ä¹¦é¦† (BnF) Gallica é¦†è—ä¸­æœç´¢æ–‡çŒ®ã€‚é€‚ç”¨åœºæ™¯ï¼šCBETA ç¼ºå°‘çš„æ•¦ç…Œå†™æœ¬ã€Pelliot è—å“ã€è¥¿åŸŸå‡ºåœŸæ–‡çŒ®ç­‰ã€‚å¯ä¸ CBETA ç»“æœäº¤å‰éªŒè¯ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "æœç´¢å…³é”®è¯ï¼ˆå¦‚ï¼šDunhuangã€æ•¦ç…Œã€Pelliotã€ç»åç­‰ï¼‰"},
                                "max_records": {"type": "INTEGER", "description": "æœ€å¤§è¿”å›æ•°é‡ï¼ˆé»˜è®¤10ï¼‰"},
                                "doc_type": {"type": "STRING", "description": "é™åˆ¶æ–‡æ¡£ç±»å‹ï¼šmanuscrit(æ‰‹ç¨¿)ã€image(å›¾åƒ)"},
                                "language": {"type": "STRING", "description": "é™åˆ¶è¯­è¨€ï¼šchi(ä¸­æ–‡)ã€san(æ¢µæ–‡)ã€tib(è—æ–‡)"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "search_gallica_dunhuang",
                        "description": "ã€Gallica æ•¦ç…Œä¸“æœã€‘ä¸“é—¨æœç´¢ Gallica ä¸­çš„æ•¦ç…Œç›¸å…³æ–‡çŒ®ï¼ˆè‡ªåŠ¨åŒ…å« Dunhuangã€Pelliotã€æ•¦ç…Œç­‰å…³é”®è¯ï¼‰ã€‚é€‚ç”¨åœºæ™¯ï¼šå¿«é€ŸæŸ¥æ‰¾æ³•å›½é¦†è—çš„æ•¦ç…Œå†™æœ¬ï¼Œç”¨äºä¸ CBETA ç‰ˆæœ¬æ¯”å¯¹ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "keyword": {"type": "STRING", "description": "é¢å¤–å…³é”®è¯ï¼ˆå¯é€‰ï¼Œå¦‚ç»åã€äººåï¼‰"},
                                "max_records": {"type": "INTEGER", "description": "æœ€å¤§è¿”å›æ•°é‡ï¼ˆé»˜è®¤10ï¼‰"}
                            },
                            "required": []
                        }
                    },
                    {
                        "name": "search_gallica_by_title",
                        "description": "ã€Gallica é¢˜åæœç´¢ã€‘åŸºäº MCP çš„ search_by_titleï¼Œé€‚åˆæŒ‰é¢˜åç²¾ç¡®å®šä½æ³•å›½é¦†è—å†™æœ¬ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "title": {"type": "STRING", "description": "æ–‡çŒ®é¢˜å"},
                                "exact_match": {"type": "BOOLEAN", "description": "æ˜¯å¦è¦æ±‚å®Œå…¨åŒ¹é…ï¼ˆé»˜è®¤ falseï¼‰"},
                                "max_results": {"type": "INTEGER", "description": "æœ€å¤§è¿”å›æ•°é‡ï¼ˆé»˜è®¤10ï¼‰"}
                            },
                            "required": ["title"]
                        }
                    },
                    {
                        "name": "search_gallica_by_author",
                        "description": "ã€Gallica ä½œè€…æœç´¢ã€‘ä½¿ç”¨ MCP çš„ search_by_authorï¼ŒæŸ¥æ‰¾ç‰¹å®šä½œè€…æˆ–æ”¶è—è€…çš„å†™æœ¬ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "author": {"type": "STRING", "description": "ä½œè€…æˆ–è—è€…å§“å"},
                                "exact_match": {"type": "BOOLEAN", "description": "æ˜¯å¦å®Œå…¨åŒ¹é…ï¼ˆé»˜è®¤ falseï¼‰"},
                                "max_results": {"type": "INTEGER", "description": "æœ€å¤§è¿”å›æ•°é‡ï¼ˆé»˜è®¤10ï¼‰"}
                            },
                            "required": ["author"]
                        }
                    },
                    {
                        "name": "search_gallica_by_subject",
                        "description": "ã€Gallica ä¸»é¢˜æœç´¢ã€‘åŸºäº MCP çš„ search_by_subjectï¼Œå¯ç”¨äºæŒ‰ä¸»é¢˜/å…³é”®è¯èšç„¦æ•¦ç…Œåˆ†ç±»ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "subject": {"type": "STRING", "description": "ä¸»é¢˜å…³é”®è¯"},
                                "exact_match": {"type": "BOOLEAN", "description": "æ˜¯å¦å®Œå…¨åŒ¹é…ï¼ˆé»˜è®¤ falseï¼‰"},
                                "max_results": {"type": "INTEGER", "description": "æœ€å¤§è¿”å›æ•°é‡ï¼ˆé»˜è®¤10ï¼‰"}
                            },
                            "required": ["subject"]
                        }
                    },
                    {
                        "name": "search_gallica_advanced",
                        "description": "ã€Gallica é«˜çº§æœç´¢ã€‘å¯¹åº” MCP çš„ advanced_searchï¼Œæ”¯æŒ Gallica CQL è¯­æ³•ç»„åˆå¤šä¸ªå­—æ®µã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "query": {"type": "STRING", "description": "CQL æŸ¥è¯¢å­—ç¬¦ä¸²"},
                                "max_results": {"type": "INTEGER", "description": "æœ€å¤§è¿”å›æ•°é‡ï¼ˆé»˜è®¤10ï¼‰"}
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "get_gallica_manifest",
                        "description": "ã€Gallica æ–‡æ¡£ç»“æ„ã€‘è·å–æŒ‡å®š Gallica æ–‡æ¡£çš„ IIIF Manifestï¼ŒåŒ…å«é¡µé¢åˆ—è¡¨ã€å…ƒæ•°æ®ã€å›¾åƒé“¾æ¥ã€‚é€‚ç”¨åœºæ™¯ï¼šå·²çŸ¥ ARK IDï¼Œéœ€è¦äº†è§£æ–‡æ¡£æœ‰å¤šå°‘é¡µã€è·å–é«˜æ¸…å›¾åƒé“¾æ¥ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "ark": {"type": "STRING", "description": "ARK æ ‡è¯†ç¬¦ï¼ˆå¦‚ ark:/12148/btv1b8304226d æˆ–çŸ­ ID btv1b8304226dï¼‰"}
                            },
                            "required": ["ark"]
                        }
                    },
                    {
                        "name": "get_gallica_pages",
                        "description": "ã€Gallica é¡µé¢æšä¸¾ã€‘è°ƒç”¨ MCP get_item_pagesï¼Œæ”¯æŒåˆ†é¡µè·å–æŸä»½å†™æœ¬çš„é¡µé¢åˆ—è¡¨ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "ark": {"type": "STRING", "description": "ARK æ ‡è¯†ç¬¦"},
                                "page": {"type": "INTEGER", "description": "æŒ‡å®šé¡µç ï¼ˆå¯é€‰ï¼‰"},
                                "page_size": {"type": "INTEGER", "description": "è¿”å›é¡µæ•°ï¼ˆå¯é€‰ï¼‰"}
                            },
                            "required": ["ark"]
                        }
                    },
                    {
                        "name": "get_gallica_page",
                        "description": "ã€Gallica å•é¡µä¿¡æ¯ã€‘è·å– Gallica æ–‡æ¡£æŸä¸€é¡µçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬åˆ†è¾¨ç‡ã€å›¾åƒ URLã€ç¼©ç•¥å›¾ã€‚é€‚ç”¨åœºæ™¯ï¼šéœ€è¦æŸ¥çœ‹æˆ–æ¯”å¯¹ç‰¹å®šé¡µé¢çš„é«˜æ¸…å›¾åƒã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "ark": {"type": "STRING", "description": "ARK æ ‡è¯†ç¬¦"},
                                "page": {"type": "STRING", "description": "é¡µç ï¼ˆå¦‚ f1ã€f2ï¼Œé»˜è®¤ f1ï¼‰"}
                            },
                            "required": ["ark"]
                        }
                    },
                    {
                        "name": "get_gallica_page_text",
                        "description": "ã€Gallica é¡µé¢æ–‡æœ¬ã€‘è°ƒç”¨ MCP get_page_textï¼Œç›´æ¥è·å– ALTO/Plain OCR å†…å®¹ï¼Œå¿«é€Ÿæ¯”å¯¹å†™æœ¬æ–‡å­—ã€‚",
                        "parameters": {
                            "type": "OBJECT",
                            "properties": {
                                "ark": {"type": "STRING", "description": "ARK æ ‡è¯†ç¬¦"},
                                "page": {"type": "INTEGER", "description": "é¡µç æ•°å­—ï¼ˆå¦‚ 1 ä»£è¡¨ f1ï¼‰"},
                                "format": {"type": "STRING", "description": "æ–‡æœ¬æ ¼å¼ plain/alto/teiï¼ˆé»˜è®¤ plainï¼‰"}
                            },
                            "required": ["ark", "page"]
                        }
                    }
                ]
            }
        ]

    def _build_prompt(self, ocr_text: str = None, image_path: str = None) -> str:
        if ocr_text:
            base_prompt = f"""ä½ æ˜¯ä¸€ä½ä½›æ•™æ–‡çŒ®è€ƒè¯ä¸“å®¶ã€‚ç°åœ¨æœ‰ä¸€æ®µå¤ç±æ–‡å­—ï¼š

{ocr_text}

"""
        else:
            base_prompt = """ä½ æ˜¯ä¸€ä½ä½›æ•™æ–‡çŒ®è€ƒè¯ä¸“å®¶ã€‚è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„å¤ç±æ–‡å­—ï¼Œæ‰¾å‡ºå…¶åœ¨ CBETA ä¸­çš„å‡ºå¤„ã€‚

"""

        return base_prompt + """## æ ¸å¿ƒç›®æ ‡
**ä¼˜å…ˆè€ƒè¯å‡ºå¤„ï¼›OCR ä»…éœ€æç‚¼å¯è¾¨è®¤ç‰‡æ®µï¼Œå¹¶æ¸…æ™°æ ‡æ³¨ä¸ç¡®å®šå­—ç¬¦ã€‚**

## å·¥ä½œæµ

### 1. å¿«é€Ÿ OCR æ‘˜è¦
- é€åˆ—æˆ–é€å¥è®°å½•å¯è¯»æ–‡å­—ï¼ˆç¤ºä¾‹ï¼š"åˆ—1ï¼šæ·¨åœŸä¸­â€¦ "ï¼‰
- ç”¨ `[?]` æˆ– `[unclear]` æ ‡è®°æ¨¡ç³Šå­—ï¼Œä¸è¦å¼ºçŒœ
- æç‚¼å…³é”®å­—/çŸ­è¯­ï¼Œä¾¿äºåç»­æœç´¢

### 2. å¹¶è¡Œæœç´¢ç­–ç•¥ï¼ˆå¯åŒæ—¶è°ƒç”¨å¤šä¸ªå·¥å…·ï¼‰
**CBETA å·¥å…·ï¼ˆä¸»çº¿ç¨‹ï¼‰ï¼š**
- `search_similar`ï¼šç”¨äº 6-50 å­—é•¿ç‰‡æ®µï¼ˆå«ä¸ç¡®å®šä½ä¹Ÿå¯ï¼‰
- `search_full_text`ï¼šç”¨äºé«˜ç½®ä¿¡åº¦å…³é”®è¯ç»„åˆ
- `search_title` / `search_toc`ï¼šæ¢ç´¢å¯èƒ½ç»åæˆ–ç« èŠ‚
- `search_variants`ï¼šè·å–å¼‚ä½“å­—ä»¥æ‰©å¤§å‘ç°

**Gallica å·¥å…·ï¼ˆæ•¦ç…Œåˆ†èº«ï¼‰â€”â€” å½“ CBETA ç»“æœä¸è¶³æˆ–éœ€è·¨ç‰ˆæœ¬æ¯”å¯¹æ—¶ï¼š**
- `search_gallica_dunhuang`ï¼šå¿«é€ŸæŸ¥æ‰¾æ³•å›½å›½å®¶å›¾ä¹¦é¦†çš„æ•¦ç…Œå†™æœ¬
- `search_gallica`ï¼šæŒ‰å…³é”®è¯æœç´¢ Pelliot è—å“ã€è¥¿åŸŸå‡ºåœŸæ–‡çŒ®
- `get_gallica_manifest`ï¼šè·å–æ–‡æ¡£ç»“æ„ä¸é«˜æ¸…å›¾åƒé“¾æ¥
- `get_gallica_page`ï¼šè·å–å•é¡µå›¾åƒ URLï¼Œç”¨äºå¤šæ¨¡æ€æ¯”å¯¹

**å­ä»»åŠ¡åˆ†å·¥ç¤ºä¾‹ï¼š**
- ä¸»çº¿ç¨‹ï¼šç»§ç»­ CBETA æ·±æŒ–ï¼Œç”¨ `search_kwic` ç²¾ç¡®å®šä½
- Gallica åˆ†èº«ï¼šåŒæ—¶æœç´¢æ•¦ç…Œå†™æœ¬ï¼Œè¿”å›å€™é€‰ ARK ä¸å›¾åƒé“¾æ¥
- å›¾åƒæ¯”å¯¹åˆ†èº«ï¼ˆå¯é€‰ï¼‰ï¼šè·å– Gallica é¡µé¢ç¼©ç•¥å›¾ï¼Œä¸åŸå›¾å¯¹ç…§

### 3. ç²¾ç¡®å®šä½ä¸äº¤å‰éªŒè¯
- å¯¹é«˜ç½®ä¿¡åº¦å€™é€‰ï¼Œä½¿ç”¨ `search_kwic` ç­‰è·å–ä¸Šä¸‹æ–‡
- æ±‡æ€»è¯æ®ï¼šåŒ¹é…å­—å¥ã€å·æ¬¡ã€ä½œè¯‘è€…ã€æœä»£
- **CBETA vs Gallica å¯¹ç…§**ï¼šåœ¨ `candidate_insights` ä¸­è®°å½•ä¸¤è€…å·®å¼‚ï¼ˆå¯é€‰ï¼‰
- æŒ‡å‡ºä»éœ€äººå·¥ç¡®è®¤çš„å·®å¼‚æˆ–ç–‘ç‚¹

### 4. ç»“æ„åŒ–è¾“å‡ºï¼ˆä¾¿äºäººå·¥æ ¡å¯¹ï¼‰
æœ€ç»ˆ JSON ä¸­è¯·ç¡®ä¿ï¼š
- `ocr_result.recognized_text`ï¼šåˆå¹¶åçš„å…¨æ–‡ï¼›`uncertain_chars`ï¼šåˆ—å‡ºæ‰€æœ‰æ ‡è®°
- `ocr_notes`ï¼šåˆ—è¡¨ï¼Œé€åˆ—/é€å¥æè¿° OCR æ‘˜è¦ï¼ˆå«ä¸ç¡®å®šè¯´æ˜ï¼‰
- `scripture_locations`ï¼šè‡³å¤š 5 æ¡å€™é€‰ï¼Œå«åŒ¹é…ç‰‡æ®µã€ç½®ä¿¡åº¦ã€è¯æ®ï¼š
  - å¯¹ **CBETA** å€™é€‰ï¼šå¯è®¾ç½® `source="CBETA"`ï¼Œ`work_id`/`canon`/`juan` ç­‰å­—æ®µå‡†ç¡®å®Œæ•´ï¼Œ`external_url` å¯ç•™ç©ºï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆ CBETA åœ¨çº¿é“¾æ¥ï¼‰ã€‚
  - å¯¹ **Gallica** å€™é€‰ï¼šå…è®¸å°†å†™æœ¬è§†ä½œâ€œè—å·â€åŠ å…¥ `scripture_locations`ï¼Œå¹¶è®¾ç½®ï¼š
    - `source="Gallica"`
    - è‹¥å·²çŸ¥ ARK ä¸é¡µç ï¼Œå°½é‡å¡«å…¥ `external_url` ä¸ºå¯ç›´æ¥æ‰“å¼€çš„ Gallica åœ¨çº¿é˜…è¯»é“¾æ¥ï¼ˆä¾‹å¦‚ `https://gallica.bnf.fr/ark:/12148/btv1b8304226d/f3.item`ï¼‰
- `key_facts`ï¼šç‰‡æ®µå…³é”®ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯é¡¹ä¸€å¥ï¼Œç›´æ¥åŸºäºå›¾åƒä¸æ­£æ–‡å¯è§å†…å®¹ï¼ˆ**ä¸**ä¾èµ–å¤–éƒ¨æ–‡çŒ®ï¼‰ï¼Œä¾‹å¦‚ï¼š
  - ç‰©è´¨å½¢æ€ï¼šå†Œå­æœ¬/å•å¶/å¯¹å¼€å¶ï¼Œé¡µæ•°æˆ–å¶æ•°ï¼Œè£…è®¢æƒ…å†µï¼Œæ®‹æŸä½ç½®ï¼ˆé¦–/å°¾/å·¦å³ä¸Šä¸‹ï¼‰ã€‚
  - é¢˜è®°ä¸å°¾é¢˜ï¼šé¦–é¢˜ã€å°¾é¢˜ã€ç½²åã€é¢˜è®°ä¸­çš„æ—¶é—´ä¸äººç‰©ã€‚
  - ç‰ˆå¼ä¸æ ‡è®°ï¼šæœ‰æ— ç§‘åˆ†æ ‡é¢˜ã€è¡Œæ•°æ æ•°ã€æœ±ç¬”åœˆç‚¹/åˆ é™¤ã€æ‚å†™ã€æ’å›¾ç­‰ã€‚
- `candidate_insights`ï¼šé€æ¡æ¦‚è¿°å€™é€‰ä¸ºä½•å€¼å¾—å…³æ³¨ï¼Œ**åŒ…æ‹¬ Gallica è¯æ®**ï¼Œä»¥åŠéœ€äººå·¥æ ¸å¯¹çš„ç‚¹
- `verification_points`ï¼šåˆ—å‡ºäººå·¥æ ¡å¯¹è¦ç‚¹ï¼ˆç–‘éš¾å­—ã€éœ€æŸ¥å·ã€**Gallica ARK/é¡µç **ã€å»ºè®®çš„ KWIC ä½ç½®ç­‰ï¼‰
- `next_actions`ï¼šç»™å®åœ°ç ”ç©¶è€…çš„åç»­å»ºè®®ï¼ˆå¦‚"å»æŸ¥ T1753 å·2 KWIC 0258a25"ã€**"æŸ¥é˜… Gallica ark:/12148/xxx f3 é¡µ"**ï¼‰
- `tools_used`ã€`search_iterations`ã€`session_id`ï¼šä¿æŒå®Œæ•´ï¼Œå¯ç”¨äºè¿½è¸ª

## ç½®ä¿¡åº¦è¯„åˆ†å»ºè®®
- **0.8-1.0**ï¼šå¤šå¤„å…³é”®å­—è¿ç»­åŒ¹é…ï¼Œå·æ¬¡/ä½œè¯‘è€…ä¸€è‡´ï¼Œ**Gallica æœ‰å¯¹åº”å†™æœ¬ä½è¯**
- **0.6-0.8**ï¼šä¸»è¦å­—å¥å»åˆï¼Œå°‘é‡ OCR æˆ–ç‰ˆæœ¬å‡ºå…¥
- **0.4-0.6**ï¼šä»…éƒ¨åˆ†å…³é”®è¯åŒ¹é…
- **0.0-0.4**ï¼šè¯æ®ä¸è¶³ï¼Œä»…ç”¨ä½œçº¿ç´¢

## æ³¨æ„äº‹é¡¹
- ä»»ä½•æ¨¡ç³Šå­—å¿…é¡»æ ‡æ³¨ `[?]`ï¼Œå¹¶åœ¨ `ocr_notes` ä¸­è¯´æ˜
- æ¯è½®æ€è€ƒæ—¶ç»™å‡º"ä¸ºä½•è°ƒç”¨æŸå·¥å…·"ä¸"å¾—åˆ°çš„äººå·¥å¯è¯»ç»“è®º"
- **å½“è°ƒç”¨ Gallica å·¥å…·æ—¶ï¼Œè¯´æ˜ä¸ CBETA çš„å¯¹ç…§æ„å›¾**
- è‹¥ Gallica è¿”å›å›¾åƒé“¾æ¥ï¼Œåœ¨ `next_actions` ä¸­é™„ä¸Šä¾›äººå·¥æŸ¥çœ‹
- ç»“æœè¦åƒ"äººå·¥æ ¡å¯¹ç¬”è®°"ï¼šçŸ­å¥ã€è¦ç‚¹ã€å¯ç›´æ¥å¼•ç”¨

è¯·å¼€å§‹åˆ†æå¹¶è°ƒç”¨å·¥å…·ã€‚"""

    def _execute_functions(
        self,
        response,
        stream_handler: Optional[StreamHandler],
    ) -> Generator[Dict, None, None]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶å¯è§†åŒ–åé¦ˆ"""
        if not response.candidates or not response.candidates[0].content.parts:
            return

        for part in response.candidates[0].content.parts:
            if part.function_call:
                fn = part.function_call
                
                # --- å¯è§†åŒ–åé¦ˆ ---
                if self.config.verbose:
                    print(f"\nğŸ¤– AI å†³å®šè°ƒç”¨å·¥å…·: {fn.name}")
                    print(f"   å‚æ•°: {fn.args}")
                
                # æ‰§è¡Œå®é™…å‡½æ•°
                if fn.name in self.tools_map:
                    try:
                        args = {k: v for k, v in (fn.args or {}).items()}
                        result = self.tools_map[fn.name](**args)

                        if self.config.verbose:
                            print(f"   âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
                            res_str = str(result)
                            print(f"   ç»“æœæ‘˜è¦: {res_str[:100]}..." if len(res_str) > 100 else f"   ç»“æœ: {res_str}")

                        summary = self._shorten_text(str(result), width=120)
                        record = {
                            "name": fn.name,
                            "args": self._serialize_args(args),
                            "result_summary": summary,
                            "status": "success",
                        }

                        self._emit_event(
                            "tool_result",
                            {"name": fn.name, "status": "success", "summary": summary},
                            stream_handler,
                        )

                        yield {
                            "function_response": {
                                "name": fn.name,
                                "response": {"result": result}
                            },
                            "tool_record": record,
                        }
                    except Exception as e:
                        print(f"   âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                        summary = self._shorten_text(str(e), width=120)
                        record = {
                            "name": fn.name,
                            "args": self._serialize_args({k: v for k, v in (fn.args or {}).items()}),
                            "result_summary": summary,
                            "status": "error",
                        }
                        self._emit_event(
                            "tool_result",
                            {
                                "name": fn.name,
                                "status": "error",
                                "summary": summary,
                            },
                            stream_handler,
                        )
                        yield {
                            "function_response": {
                                "name": fn.name,
                                "response": {"error": str(e)}
                            },
                            "tool_record": record,
                        }
                else:
                    print(f"   âš ï¸ æœªçŸ¥å·¥å…·: {fn.name}")
                    self._emit_event(
                        "error",
                        {"message": f"æœªçŸ¥å·¥å…·: {fn.name}"},
                        stream_handler,
                    )

    def _serialize_args(self, args: Dict[str, Any]) -> Dict[str, Any]:
        """å°†å·¥å…·å‚æ•°è½¬æ¢ä¸º JSON å‹å¥½çš„å½¢å¼"""
        def convert(value: Any) -> Any:
            if isinstance(value, (str, int, float, bool)) or value is None:
                return value
            if isinstance(value, dict):
                return {k: convert(v) for k, v in value.items()}
            if isinstance(value, (list, tuple)):
                return [convert(v) for v in value]
            return str(value)

        return {k: convert(v) for k, v in args.items()}

    def _shorten_text(self, text: str, width: int) -> str:
        cleaned = " ".join(str(text).split())
        if not cleaned:
            return ""
        return textwrap.shorten(cleaned, width=width, placeholder="...")

    def _extract_round_text_summary(self, parts: List[types.Part]) -> str:
        texts = []
        for part in parts:
            if part.text and not part.function_call:
                cleaned = " ".join(part.text.split())
                if cleaned:
                    texts.append(cleaned)
        if not texts:
            return ""
        joined = " ".join(texts)
        return self._shorten_text(joined, width=600)

    def _persist_round_summary(
        self,
        session_id: str,
        round_index: int,
        summary: str,
        tool_calls: List[Dict[str, Any]],
        notes: List[str],
    ):
        payload = {
            "round_index": round_index,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "summary": summary,
            "tool_calls": tool_calls,
            "notes": notes,
        }
        self.session_manager.save_round(session_id, payload)

    def _build_history_from_rounds(self, session_id: str) -> List[types.Content]:
        rounds = self.session_manager.load_rounds(session_id)
        if not rounds:
            return []
        return build_round_history_contents(rounds)

    def _force_structured_output(
        self,
        history: List[types.Content],
        session_id: str,
    ) -> Optional[FinalAnswer]:
        """
        å¼ºåˆ¶ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼ˆæœ€ç»ˆè½®ï¼‰ï¼Œä½¿ç”¨æ›´å¤šé‡è¯•æ¬¡æ•°ã€‚
        """
        if self.config.verbose:
            print("\nğŸ”„ ã€æœ€ç»ˆè½®ã€‘å¼ºåˆ¶ç”Ÿæˆç»“æ„åŒ–ç­”æ¡ˆ...")
        
        final_prompt = """è¯·æ ¹æ®ä¸Šè¿°æ‰€æœ‰åˆ†æï¼Œè¾“å‡ºæœ€ç»ˆçš„ç»“æ„åŒ– JSON ç­”æ¡ˆã€‚

å³ä½¿ä¿¡æ¯ä¸å®Œæ•´ï¼Œä¹Ÿè¯·å°½é‡å¡«å†™ï¼š
- ocr_result.recognized_text: è¯†åˆ«å‡ºçš„æ–‡å­—ï¼ˆä¸ç¡®å®šçš„ç”¨[?]æ ‡æ³¨ï¼‰
- scripture_locations: å¯èƒ½çš„ç»æ–‡å‡ºå¤„åˆ—è¡¨ï¼ˆæŒ‰ç½®ä¿¡åº¦æ’åºï¼‰
- reasoning: ä½ çš„æ¨ç†è¿‡ç¨‹æ‘˜è¦

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON Schema è¾“å‡ºã€‚"""
        
        history.append(types.Content(role="user", parts=[types.Part(text=final_prompt)]))
        
        # ä½¿ç”¨å®˜æ–¹æ¨èçš„ structured output é…ç½®ï¼š
        # - response_mime_type å›ºå®šä¸º application/json
        # - response_schema ä¼ å…¥ Pydantic ç”Ÿæˆçš„ JSON Schema
        final_config = types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=FinalAnswer.model_json_schema(),
        )
        
        try:
            final_resp = self._call_with_retry(
                self.client.models.generate_content,
                model=self.config.model_name,
                contents=history,
                config=final_config,
                max_retries=self.config.final_retries,
                retry_interval=self.config.retry_interval,
            )
            
            if final_resp.text:
                result = FinalAnswer.model_validate_json(final_resp.text)
                # å¡«å…… session_id
                result.session_id = session_id
                return result
        except Exception as e:
            print(f"âŒ æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}")
        
        return None

    def analyze_and_locate(
        self,
        ocr_text: str = None,
        image_path: str = None,
        stream_handler: Optional[StreamHandler] = None,
        resume_session_id: Optional[str] = None,
        include_final_output: bool = True,
    ) -> FinalAnswer:
        """
        ä¸»æµç¨‹ï¼šåˆ†æå¹¶å®šä½ç»æ–‡å‡ºå¤„ã€‚
        
        æµç¨‹è¯´æ˜ï¼š
        - æœ€å¤šè¿›è¡Œ max_tool_rounds è½®å·¥å…·è°ƒç”¨ï¼ˆé»˜è®¤5è½®ï¼‰
        - AI å¯éšæ—¶é€‰æ‹©ä¸è°ƒç”¨å·¥å…·ï¼Œæå‰ç»“æŸ
        - å¯é€‰æ‹©è·³è¿‡æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºï¼Œä»…ä¾é è½®æ¬¡å­˜æ¡£
        - æ™®é€šè½®é‡è¯• normal_retries æ¬¡ï¼Œæœ€ç»ˆè½®é‡è¯• final_retries æ¬¡
        """
        history: List[types.Content] = []
        if resume_session_id:
            session_id = resume_session_id
            history.extend(self._build_history_from_rounds(session_id))
            if self.config.verbose:
                print(f"ğŸ”„ ç»§ç»­ä¼šè¯: {session_id}")
        else:
            session_id = self.session_manager.create_session()
            if self.config.verbose:
                print(f"ğŸ”µ å¼€å§‹æ–°ä¼šè¯: {session_id}")
                print(f"   æœ€å¤šå·¥å…·è°ƒç”¨è½®æ•°: {self.config.max_tool_rounds}")
        prompt = self._build_prompt(ocr_text, image_path)
        
        # å¦‚æœæœ‰å›¾ç‰‡ï¼ŒåŠ è½½å›¾ç‰‡
        if image_path:
            try:
                from PIL import Image
                img = Image.open(image_path)
                if self.config.verbose:
                    print(f"ğŸ–¼ï¸ å·²åŠ è½½å›¾ç‰‡: {image_path}")
                mime_type = Image.MIME.get(img.format, "image/png")
                with open(image_path, "rb") as f:
                    image_bytes = f.read()
                image_part = types.Part.from_bytes(data=image_bytes, mime_type=mime_type)
                contents = [prompt, image_part]
            except Exception as e:
                print(f"âŒ åŠ è½½å›¾ç‰‡å¤±è´¥: {e}")
                contents = [prompt]
        else:
            contents = [prompt]
        
        # åˆå§‹å¯¹è¯å†å²
        parts = []
        for content in contents:
            if isinstance(content, str):
                parts.append(types.Part(text=content))
            elif isinstance(content, types.Part):
                parts.append(content)
            else:
                raise TypeError("Unsupported content type for Gemini request.")

        history.append(types.Content(role="user", parts=parts))
        
        tool_round = 0  # å·¥å…·è°ƒç”¨è½®æ•°è®¡æ•°
        successful_rounds = 0
        
        # å·¥å…·è°ƒç”¨é˜¶æ®µï¼ˆæœ€å¤š max_tool_rounds è½®ï¼‰
        while tool_round < self.config.max_tool_rounds:
            tool_round += 1
            if self.config.verbose:
                print(f"\nğŸ”„ ç¬¬ {tool_round}/{self.config.max_tool_rounds} è½®æ€è€ƒ...")
            
            generate_config = types.GenerateContentConfig(
                temperature=1.0,
                max_output_tokens=8192,
                thinking_config=types.ThinkingConfig(
                    thinking_level=self.config.thinking_level,
                    include_thoughts=True
                ),
                tools=self.tools_declarations,
                tool_config=types.ToolConfig(
                    function_calling_config=types.FunctionCallingConfig(
                        mode="AUTO"
                    )
                ),
            )
            
            try:
                response = self._call_with_retry(
                    self._generate_with_stream,
                    contents=history,
                    config=generate_config,
                    stream_handler=stream_handler,
                    max_retries=self.config.normal_retries,
                    retry_interval=self.config.retry_interval,
                )
            except Exception as e:
                print(f"âŒ ç¬¬ {tool_round} è½® API è°ƒç”¨å¤±è´¥: {e}")
                break  # è·³å‡ºå¾ªç¯ï¼Œè¿›å…¥æœ€ç»ˆç»“æ„åŒ–è¾“å‡º

            # å¤„ç†å“åº”
            if not response or not response.candidates:
                print("âš ï¸ æ— å“åº”å€™é€‰")
                break
                
            candidate = response.candidates[0]
            content = candidate.content
            round_summary = self._extract_round_text_summary(content.parts)
            tool_records: List[Dict[str, Any]] = []
            json_result: Optional[FinalAnswer] = None
            should_break = False
            
            successful_rounds += 1

            # å°†æ¨¡å‹å“åº”åŠ å…¥å†å²
            history.append(content)
            
            # æ£€æŸ¥å·¥å…·è°ƒç”¨
            has_tool_call = any(part.function_call for part in content.parts)
            
            if has_tool_call:
                # æ‰§è¡Œå·¥å…·
                tool_outputs = list(self._execute_functions(response, stream_handler))
                
                parts = []
                for output in tool_outputs:
                    parts.append(types.Part.from_function_response(
                        name=output["function_response"]["name"],
                        response=output["function_response"]["response"]
                    ))
                    if "tool_record" in output:
                        tool_records.append(output["tool_record"])
                
                history.append(types.Content(role="user", parts=parts))
            else:
                # AI é€‰æ‹©ä¸è°ƒç”¨å·¥å…·ï¼Œå°è¯•ä»å›å¤ä¸­æå– JSON
                text_response = "".join([p.text for p in content.parts if p.text])
                
                if self.config.verbose:
                    print(f"\nğŸ“ AI å›å¤ï¼ˆç¬¬ {tool_round} è½®æ— å·¥å…·è°ƒç”¨ï¼‰")
                
                if "{" in text_response and "}" in text_response:
                    try:
                        start = text_response.find("{")
                        end = text_response.rfind("}") + 1
                        json_str = text_response[start:end]
                        result = FinalAnswer.model_validate_json(json_str)
                        result.session_id = session_id
                        json_result = result
                    except Exception as e:
                        if self.config.verbose:
                            print(f"   JSON è§£æå¤±è´¥: {e}ï¼Œè¿›å…¥æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºè½®...")
                
                if not json_result:
                    should_break = True

            notes: List[str] = []
            if not round_summary:
                notes.append("æœ¬è½®æœªäº§ç”Ÿæ–‡æœ¬æ‘˜è¦")
            if not has_tool_call:
                notes.append("æœ¬è½®æœªè°ƒç”¨å·¥å…·")
            if json_result:
                notes.append("æå‰ç”Ÿæˆç»“æ„åŒ–ç»“æœï¼Œç»“æŸæœ¬è½®")

            self._persist_round_summary(
                session_id,
                round_index=tool_round,
                summary=round_summary,
                tool_calls=tool_records,
                notes=notes,
            )

            if json_result:
                self.session_manager.save_session(session_id, history)
                return json_result
            if should_break:
                break
        
        # ===== æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºè½®ï¼ˆä¸è®¡å…¥å·¥å…·è°ƒç”¨è½®æ•°ï¼‰ =====
        if self.config.verbose:
            print(f"\nğŸ“Š å·¥å…·è°ƒç”¨é˜¶æ®µç»“æŸï¼ˆå…± {tool_round} è½®ï¼‰")
        
        if successful_rounds == 0:
            if self.config.verbose:
                print("âš ï¸ æ‰€æœ‰å·¥å…·è°ƒç”¨è½®å‡æœªæˆåŠŸï¼Œè·³è¿‡æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºã€‚")
            self.session_manager.save_session(session_id, history)
            return None

        if not include_final_output:
            if self.config.verbose:
                print("âš ï¸ å·²é…ç½®è·³è¿‡æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºï¼ˆä»…ä¿ç•™è½®æ¬¡å­˜æ¡£ï¼‰ã€‚")
            self.session_manager.save_session(session_id, history)
            return None

        if self.config.verbose:
            print("ğŸ“Š è¿›å…¥æœ€ç»ˆç»“æ„åŒ–è¾“å‡ºï¼ˆç»“æ„åŒ– JSONï¼‰...")

        result = self._force_structured_output(history, session_id)
        
        # ä¿å­˜ä¼šè¯
        self.session_manager.save_session(session_id, history)
        
        return result

    def resume_with_session(
        self,
        session_id: str,
        ocr_text: str = None,
        image_path: str = None,
        stream_handler: Optional[StreamHandler] = None,
        include_final_output: bool = True,
    ) -> FinalAnswer:
        """
        ä»å·²æœ‰ä¼šè¯çš„è½®æ¬¡å­˜æ¡£é‡å»ºä¸Šä¸‹æ–‡ï¼Œç»§ç»­æˆ–é‡æ–°å‘èµ·æ€è€ƒã€‚
        """
        return self.analyze_and_locate(
            ocr_text=ocr_text,
            image_path=image_path,
            stream_handler=stream_handler,
            resume_session_id=session_id,
            include_final_output=include_final_output,
        )
